\documentclass[11pt,a4paper]{article}
\usepackage[spanish,es-nodecimaldot]{babel}	% Utilizar español
\usepackage[utf8]{inputenc}					% Caracteres UTF-8
\usepackage{graphicx}						% Imagenes
\usepackage[hidelinks]{hyperref}			% Poner enlaces sin marcarlos en rojo
\usepackage{fancyhdr}						% Modificar encabezados y pies de pagina
\usepackage{float}							% Insertar figuras
\usepackage[textwidth=390pt]{geometry}		% Anchura de la pagina
\usepackage[nottoc]{tocbibind}				% Referencias (no incluir num pagina indice en Indice)
\usepackage{enumitem}						% Permitir enumerate con distintos simbolos
\usepackage[T1]{fontenc}					% Usar textsc en sections
\usepackage{amsmath}						% Símbolos matemáticos
\usepackage{listings}
\usepackage{color}

 
\definecolor{codegreen}{rgb}{0,0.6,0}
\definecolor{codegray}{rgb}{0.5,0.5,0.5}
\definecolor{codepurple}{rgb}{0.58,0,0.82}
\definecolor{backcolour}{rgb}{0.99,0.99,0.99}
 
\lstdefinestyle{mystyle}{
    backgroundcolor=\color{backcolour},   
    commentstyle=\color{codegreen},
    keywordstyle=\color{magenta},
    numberstyle=\tiny\color{codegray},
    stringstyle=\color{codepurple},
    basicstyle=\footnotesize,
    breakatwhitespace=false,         
    breaklines=true,                 
    captionpos=b,                    
    keepspaces=true,                 
    numbers=left,                    
    numbersep=5pt,                  
    showspaces=false,                
    showstringspaces=false,
    showtabs=false,                  
    tabsize=2
}
 
\lstset{style=mystyle, language=Python}

% Comando para poner el nombre de la asignatura
\newcommand{\asignatura}{Inteligencia de Negocio}
\newcommand{\autor}{José María Sánchez Guerrero}
\newcommand{\titulo}{Práctica 1}
\newcommand{\subtitulo}{Resolución de problemas de clasificación y análisis experimental.}

% Configuracion de encabezados y pies de pagina
\pagestyle{fancy}
\lhead{\autor{}}
\rhead{\asignatura{}}
\lfoot{Grado en Ingeniería Informática}
\cfoot{}
\rfoot{\thepage}
\renewcommand{\headrulewidth}{0.4pt}		% Linea cabeza de pagina
\renewcommand{\footrulewidth}{0.4pt}		% Linea pie de pagina

\begin{document}
\pagenumbering{gobble}

% Pagina de titulo
\begin{titlepage}

\begin{minipage}{\textwidth}

\centering

\includegraphics[scale=0.5]{img/ugr.png}\\

\textsc{\Large \asignatura{}\\[0.2cm]}
\textsc{GRADO EN INGENIERÍA INFORMÁTICA}\\[1cm]

\noindent\rule[-1ex]{\textwidth}{1pt}\\[1.5ex]
\textsc{{\Huge \titulo\\[0.5ex]}}
\textsc{{\Large \subtitulo\\}}
\noindent\rule[-1ex]{\textwidth}{2pt}\\[3.5ex]

\end{minipage}

\vspace{0.5cm}

\begin{minipage}{\textwidth}

\centering

\textbf{Autor}\\ {\autor{}}\\[2.5ex]
\textbf{Rama}\\ {Computación y Sistemas Inteligentes}\\[2.5ex]
\vspace{0.3cm}

\includegraphics[scale=0.3]{img/etsiit.jpeg}

\vspace{0.3cm}
\textsc{Escuela Técnica Superior de Ingenierías Informática y de Telecomunicación}\\
\vspace{1cm}
\textsc{Curso 2020-2021}
\end{minipage}
\end{titlepage}

\pagenumbering{arabic}
\tableofcontents
\thispagestyle{empty}				% No usar estilo en la pagina de indice

\newpage

\setlength{\parskip}{1em}



\section{Introducción}

En este trabajo vamos a analizar el comportamiento de distintos algoritmos de clasificación en el problema propuesto. Disponemos
de un dataset, llamado \textit{''Mammographic Mass dataset''}, en el cual se desea predecir el tipo de tumor (benigno o maligno)
en una serie de mamografías realizadas para un estudio sobre el cáncer de mama. Este estudio lo vamos a realizar gracias a los
siguientes atributos proporcionados en el dataset:

\begin{itemize}
	\item \textbf{BI-RADS.} Este parámetro representa un control de calidad de las mamografías. Consta de 7 categorías distintas,
		  en las que, cuanto más alto sea el valor, hay una mayor probabilidad de que sea maligno.

	\item \textbf{Edad} del paciente.
	
	\item \textbf{Forma de la masa.} Dependiendo de como sea la masa anormal detectada, se clasifica como \textbf{R}edondeada,
		  \textbf{O}valada, \textbf{L}obulada, \textbf{I}rregular ó \textbf{N}o definida.

	\item \textbf{Margen de masa.} Circumscribed = 1, microlobulated = 2, obscured = 3, ill-defined = 4, spiculated = 5 (nominal).
	
	\item \textbf{Densidad de la masa.} Valores entre 1 y 4, siendo 1 la más alta y 4 contenido graso (no tumoral).
	
	\item \textbf{Severidad.} Es el atributo que se desea predecir, es decir, si es un tumor benigno o maligno.	

\end{itemize}

En el dataset hay datos de 961 pacientes, sin embargo, nos gustaría dejar un porcentaje para validar el modelo y así ver cómo va
entrenando los datos. Posteriormente, se explicará cómo se ha determinado qué datos son los de entrenamiento y cuáles son los de
test.

\newpage

\section{Procesado de datos}

Lo primero que tenemos que hacer es mostrar varios de los datos que tenemos y analizarlos. En mi caso vamos a sacar las 5 primeras
filas:

\begin{table}[H]
    \centering
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{|c|c|c|c|c|c|c|}
    \hline
    \textbf{} & \textbf{BI-RADS} & \textbf{Age} & \textbf{Shape} & \textbf{Margin} & \textbf{Density} & \textbf{Severity} \\ \hline
    \textbf{0} & 5.0 & 67.0 & L & 5.0 & 3.0 & maligno \\ \hline
    \textbf{1} & 4.0 & 43.0 & R & 1.0 & NaN & maligno \\ \hline
    \textbf{2} & 5.0 & 58.0 & I & 5.0 & 3.0 & maligno \\ \hline
    \textbf{3} & 4.0 & 28.0 & R & 1.0 & 3.0 & benigno \\ \hline
    \textbf{4} & 5.0 & 74.0 & R & 5.0 & NaN & maligno \\ \hline
    \end{tabular}%
    }
\end{table}

Podemos observar que tenemos tanto datos numéricos, como datos categóricos, como ya comentamos en la introducción. También podemos
observar que tenemos varias celdas con datos erróneos o perdidos (representados con el valor $NaN$), por lo que será importante
procesarlos para que nuestros algoritmos funcionen correctamente. Primero veamos qué cantidad de estos datos nulos tenemos:

\begin{table}[H]
    \centering
    \begin{tabular}{|l|l|}
    \hline
    \multicolumn{1}{|c|}{\textbf{BI-RADS}} & 2 \\ \hline
    \textbf{Age} & 5 \\ \hline
    \textbf{Shape} & 0 \\ \hline
    \textbf{Margin} & 48 \\ \hline
    \textbf{Density} & 76 \\ \hline
    \textbf{Severity} & 0 \\ \hline
    \end{tabular}
\end{table}

Son una cantidad bastante alta de datos, en comparación con la cantidad de datos totales que tenemos. Por lo tanto, eliminar toda
las filas que contengan uno, puede dejarnos con muy pocos datos para entrenar y validar, y que el modelo sea más débil. No obstante,
el introducir datos para reemplazar uno faltante ha de realizarse con cuidado, ya que no son datos reales.

También tenemos que tener en cuenta cuál es la distribución de estos datos antes de trabajar con ellos. Es decir, tenemos que
asegurarnos de no sesgar nuestros datos si los eliminamos. Si hay algún tipo de correlación, tendríamos que intentar completarlos
de alguna forma. Para ello, vamos a generar una gráfica para cada uno de los atributos del $dataset$, en la que mostraremos la
cantidad de datos antes y después de eliminarlos, y asi ver cómo están distribuidos.

\newpage
Los resultados son los siguientes:

\begin{figure}[H]
\centering

\begin{minipage}{0.5\textwidth}
    \centering
    \includegraphics[scale=0.35]{img/birads-distribution.png}
\end{minipage}%
\begin{minipage}{0.5\textwidth}
    \centering
    \includegraphics[scale=0.35]{img/age-distribution.png}
\end{minipage}

\end{figure}


\begin{figure}[H]
\centering

\begin{minipage}{0.5\textwidth}
    \centering
    \includegraphics[scale=0.35]{img/shape-distribution.png}
\end{minipage}%
\begin{minipage}{0.5\textwidth}
    \centering
    \includegraphics[scale=0.35]{img/margin-distribution.png}
\end{minipage}

\end{figure}


\begin{figure}[H]
\centering

\begin{minipage}{0.5\textwidth}
    \centering
    \includegraphics[scale=0.35]{img/density-distribution.png}
\end{minipage}%
\begin{minipage}{0.5\textwidth}
    \centering
    \includegraphics[scale=0.35]{img/severity-distribution.png}
\end{minipage}

\end{figure}

Podemos observar que los datos nulos están distribuidos aleatoriamente entre los atributos, por lo que podremos eliminarlos del
$dataset$ sin ningún problema (y teniendo en cuenta que tendremos menos datos para trabajar).

% PROBAR REEMPLAZANDO LOS DATOS CON ALEATORIOS
% \textit{Pandas} nos proporciona la función ''\textit{fillna()}'' para reemplazar los valores faltantes con un valor específico



\section{Configuración de algoritmos}
Para todos los algoritmos hemos procedido de la misma manera, y así evaluarlos a todos en igualdad de condiciones. Para comenzar,
declaramos el clasificador con sus parámetros correspondientes (en nuestro caso, las primeras evaluaciones han sido con los
parámetros por defecto y una semilla $random\_state=0$).

Posteriormente, hacemos las predicciones correspondientes para los datos de entrenamiento. Lo hacemos mediante validación cruzada
de 5 particiones, gracias a la función:
$$cross\_val\_predict(classifier, x\_train, y\_train, cv=5)$$

Por último, para evaluar los resultados obtenidos vamos a usar:
\begin{itemize}
    \item \textbf{Classification report.} Crea un informe que muestra las principales métricas de clasificación: precisión, recall,
          f1-score, y promedios macro, ponderado y de la muestra.
    \item \textbf{Score.} Misma medida del informe anterior mostrada con un poco más de precisión.
    \item \textbf{AUC Score.} Métrica que calcula el área bajo la curva ROC generada a partir de las predicciones.
    \item \textbf{Confusion matrix.} Muestra una matriz para evaluar la precisión de la clasificación. Cada fila representa las
          instancias de una clase predicha, mientras que cada columna representa las instancias reales de ésta.
\end{itemize}

Los algoritmos que evaluaremos han sido elegidos porque, cada uno de ellos, tiene una forma de procesar los datos diferente a todos
los demás. Estos algoritmos son los siguientes:


\subsection{K-Nearest-Neighbors (k-NN)}
Comenzamos por este algoritmo ya que es uno de los más utilizados, debido a su simplicidad. Este algoritmo funciona de la siguiente
manera. Cuando tenemos un nuevo ejemplo a clasificar, calcula la distancia (Euclídea) con respecto a los datos ya existentes, y
considerando los $k$ más cercanos, determina si pertenece a una clase u otra.

\newpage
A la hora de implementarlo lo hacemos de la siguiente forma:
$$KnnClf = KNeighborsClassifier(n\_neighbors=5)$$

Seleccionamos un número \textbf{k=5} de vecinos a evaluar y dejamos el resto de parámetros que trae el algoritmo por defecto. El
parámetro anterior es el más relevante, sin embargo, algunos otros interesantes a estudiar pueden ser, por ejemplo: \textbf{p},
que sirve para cambiar el tipo de distancia utilizada (Euclídea, Manhattan o Minkowski); ó \textbf{weights}, que determina la
influencia de los vecinos en la predicción (todos ponderan igual, los cercanos influyen más o tu propia función).

\subsection*{Resultados obtenidos}
% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table}[H]
    \centering
    \begin{tabular}{c|cccc}
        \textbf{} & \textbf{precision} & \textbf{recall} & \textbf{f1-score} & \textbf{support} \\ \hline
        \textbf{0} & 0.80 & 0.82 & 0.81 & 347 \\
        \textbf{1} & 0.81 & 0.78 & 0.79 & 330 \\ \hline
        \textbf{accuracy} &  &  & 0.80 & 677 \\
        \textbf{macro avg} & 0.80 & 0.80 & 0.80 & 677 \\
        \textbf{weighted avg} & 0.80 & 0.80 & 0.80 & 677
    \end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{img/matrix-knn.png}    
\end{figure}
$$\textbf{SCORE:  } 0.7991137370753324$$
$$\textbf{AUC score:  } 0.7986900707361801$$


\subsection{Decision Tree}
Este clasificador, como su propio nombre indica, es un árbol en el que cada \textbf{hoja} es una clase y cada \textbf{nodo} es
un nodo de decisión con una prueba simple a realizar.

El algoritmo funciona de la siguiente forma. Todos los ejemplos de entrenamiento comienzan desde el nodo raíz y se dividen
recursivamente los ejemplos en base a los atributos seleccionados. Esta selección de atributos se suele realizar mediante el
criterio ''\textit{gini}'', pero también hay otros como ''\textit{InfoGain}'' o ''\textit{GainRatio}''. Posteriormente,
quitamos las ramas con ruido o con datos anómalos.

A la hora de implementarlo lo hacemos de la siguiente forma:
$$DecTreeClf = tree.DecisionTreeClassifier(random_state=0)$$

El parámetro \textbf{random\_state} nos sirve para seleccionar la semilla. El resto de parámetros los dejamos por defecto, ya
que la mayoría son utilizados para limitar el número de hojas, el número de características, etc. que en nuestro ejemplo no
necesitaremos. También tenemos el parámetro \textbf{criterion}, que nos sirve para elegir el criterio de selección de atributos
comentado anteriormente.

\subsection*{Resultados obtenidos}
% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table}[H]
    \centering
    \begin{tabular}{c|cccc}
        \textbf{} & \textbf{precision} & \textbf{recall} & \textbf{f1-score} & \textbf{support} \\ \hline
        \textbf{0} & 0.75 & 0.82 & 0.78 & 347 \\
        \textbf{1} & 0.79 & 0.72 & 0.75 & 330 \\ \hline
        \textbf{accuracy} & 0.77 & 677 & 0.80 & 677 \\
        \textbf{macro avg} & 0.77 & 0.77 & 0.77 & 677 \\
        \textbf{weighted avg} & 0.77 & 0.77 & 0.77 & 677
    \end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{img/matrix-tree.png}    
\end{figure}
$$\textbf{SCORE:  } 0.7666174298375185$$
$$\textbf{AUC score:  } 0.7653567374028469$$


\subsection{Naive-Bayes}
Se ha utilizado porque es el modelo de red bayesiana orientada a clasificación más simple. Este algoritmo se considera un
estándar y sus resultados son competitivos, pese a utilizar una hipótesis poco realista. Es decir, suponemos que todos los
atributos son independientes a partir de su clase, asi que la hipótesis MAP (Máximo a posteriori) en un Naive-Bayes queda así:
$$C_{MAP} = \arg _{c\epsilon \Omega_C}maxP(c|a_1,...,a_n) = \arg _{c\epsilon \Omega_C}maxP(c)\prod_{i=1}^{n}P(a_i|c)$$

En la práctica, existen dependencias entre variables, por lo que puede llevar a una falta de precisión que no se puede retocar
en un clasificador como este (existen redes de creencia bayesianas para solucionar esto).

A la hora de implementarlo lo hacemos de la siguiente forma:
$$GaussianClf = GaussianNB()$$

No ponemos ningún parámetro ya que es un clasificador que no se puede modelar o retocar, como acabamos de decir.

\subsection*{Resultados obtenidos}
% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table}[H]
    \centering
    \begin{tabular}{c|cccc}
        \textbf{} & \textbf{precision} & \textbf{recall} & \textbf{f1-score} & \textbf{support} \\ \hline
        \textbf{0} & 0.85 & 0.78 & 0.81 & 347 \\
        \textbf{1} & 0.79 & 0.85 & 0.82 & 330 \\ \hline
        \textbf{accuracy} & 0.82 & 677 & 0.80 & 677 \\
        \textbf{macro avg} & 0.82 & 0.82 & 0.82 & 677 \\
        \textbf{weighted avg} & 0.82 & 0.82 & 0.82 & 677
    \end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{img/matrix-naivebayes.png}    
\end{figure}
$$\textbf{SCORE:  } 0.8153618906942393$$
$$\textbf{AUC score:  } 0.8162474893022443$$


\subsection{Neural Network}
Estos algoritmos están basados en los propios sistemas nerviosos biológicos:
\begin{figure}[H]
    \centering
    \includegraphics[scale=0.35]{img/neural-network.png}    
\end{figure}

Como podemos ver en la figura, cada señal que llega a las dendritas \{$x_1,x_2,...,x_n$\} serían nuestros datos de entrada
del modelo. Las sinapsis o puntos de conexión con otra neurona, serían los pesos \{$w_1,w_2,...,w_n$\} que ponderan a las
entradas: \textbf{positivo} es una sinapsis excitadora y \textbf{negativo} es una sinapsis inhibidora.

Después, la actividad interna de cada célula sería la sumatoria entre cada una de las conexiones anteriores, y por último, la
\textbf{función de activación} que, dadas estas entradas, define una salida para el modelo:
$$y_j = f(Net_j - \theta_j) = f(\sum w_{ji} \cdot x_i - \theta)$$

Para este trabajo, no vamos a implementar una red neuronal desde cero, ya que es una tarea bastante compleja. Sin embargo,
vamos a utilizar un \textbf{MultiLayer Perceptron (MLP)}, que es una red neuronal compuesta por: una capa de entrada, capas
ocultas (o \textit{hidden layers}) y una capa de salida. Excepto los datos de entrada, cada nodo es una neurona que utiliza
una función de activación no lineal (sigmoidal es la más común), y en el entrenamiento utiliza la técnica de \textit{backtracking}

A la hora de implementarlo lo haremos de la siguiente forma:
$$PerceptronClf = MLPClassifier(hidden\_layer\_sizes=100, random\_state=0)$$

Aquí podemos ver la cantidad de capas ocultas que queremos que tenga nuestra red. Es el parámetro más importante, ya que
cuanto más alto sea, más aprenderá de los datos que tenemos. Esto no quiere decir que tengamos que poner un valor muy alto,
ya que puede causar sobreaprendizaje en nuestro modelo. El otro parámetro que aparece, al igual que en los otros clasificadores,
nos sirve para seleccionar la semilla.

También existen otros parámetros importantes, como pueden ser: \textbf{activation}, con la que podemos seleccionar la función
de activación a utilizar; \textbf{early\_stopping}, que sirve para finalizar el entrenamiento si no se mejora durante un número
X de iteraciones; o parámetros relacionados con los pesos como \textbf{solver} (para la optimización de los pesos), \textbf{
learning\_rate} (tasa de aprendizaje) ó \textbf{tol} (tolerancia).

\subsection*{Resultados obtenidos}
% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table}[H]
    \centering
    \begin{tabular}{c|cccc}
        \textbf{} & \textbf{precision} & \textbf{recall} & \textbf{f1-score} & \textbf{support} \\ \hline
        \textbf{0} & 0.82 & 0.87 & 0.85 & 347 \\
        \textbf{1} & 0.86 & 0.80 & 0.83 & 330 \\ \hline
        \textbf{accuracy} & 0.84 & 677 & 0.80 & 677 \\
        \textbf{macro avg} & 0.84 & 0.84 & 0.84 & 677 \\
        \textbf{weighted avg} & 0.84 & 0.84 & 0.84 & 677
    \end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{img/matrix-neuralnetwork.png}    
\end{figure}
$$\textbf{SCORE:  } 0.8360413589364845$$
$$\textbf{AUC score:  } 0.8350842721159724$$

\subsection{Support Vector Machine (SVM)}
El último algoritmo que vamos a utilizar es uno de los más populares en cuanto a la clasificación binaria. Una SVM construye
un hiperplano entre las dos clases de forma que la separación entre ellas se amplie al máximo. Se van transformando los datos
de entrada en un espacio de caracteristicas mediante el \textbf{producto interno (escalar)}.

A la hora de implementarlo lo haremos de la siguiente forma:
$$SvmClf = SVC(random_state=0, gamma='auto')$$

El primer parámetro que tenemos aquí es la semilla, al igual que en los otros. El siguiente parámetro es para seleccionar
el coeficiente del \textbf{kernel} (el cual también es otro parámetro que también se podrá modificar).

También tenemos otros parámetros como son la \textbf{C}, para la regularazación; \textbf{tol} o tolerancia, como en las redes
neuronales; o hasta un \textbf{max\_iter} por si queremos poner un máximo de iteraciones.

\subsection*{Resultados obtenidos}
% Please add the following required packages to your document preamble:
% \usepackage{graphicx}
\begin{table}[H]
    \centering
    \begin{tabular}{c|cccc}
        \textbf{} & \textbf{precision} & \textbf{recall} & \textbf{f1-score} & \textbf{support} \\ \hline
        \textbf{0} & 0.81 & 0.88 & 0.84 & 347 \\
        \textbf{1} & 0.86 & 0.78 & 0.82 & 330 \\ \hline
        \textbf{accuracy} & 0.83 & 677 & 0.80 & 677 \\
        \textbf{macro avg} & 0.83 & 0.83 & 0.83 & 677 \\
        \textbf{weighted avg} & 0.83 & 0.83 & 0.83 & 677
    \end{tabular}
\end{table}

\begin{figure}[H]
    \centering
    \includegraphics[scale=0.5]{img/matrix-neuralnetwork.png}    
\end{figure}
$$\textbf{SCORE:  } 0.8301329394387001$$
$$\textbf{AUC score:  } 0.8289494367304165$$



\newpage
\section{Análisis de los resultados}
Podemos observar que tenemos aproximadamente un 80\% de precisión, es decir, el modelo ha acertado un 80\% de los casos que se le
ha propuesto. No 


\section{Interpretación de los resultados}



\section{Conclusión} % MODELO FINAL SELECCIONADO


\section{Bibliografía}
% https://es.mathworks.com/discovery/support-vector-machine.html

\end{document}